{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c16f42cc-b4a5-4bda-9444-2b33921df22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "AVAILABLE_GPU = 1\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= f\"{AVAILABLE_GPU}\" # ALWAYS look the one with 0% usage\n",
    "tf_device=f'/gpu:{AVAILABLE_GPU}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "190fd3a6-f7bd-4061-983c-d55d5f267b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/historynlp/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd\n",
    "import re\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "from torch.nn.functional import normalize\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9e8a7c6-9dfc-477c-9af7-05a8df9f84ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was a lot of \u001b[91mperson\u001b[0ms."
     ]
    }
   ],
   "source": [
    "def printred(text, word):\n",
    "    index = 0\n",
    "    while index < len(text):\n",
    "        if text[index:index+len(word)] == word:\n",
    "            print('\\033[91m' + text[index:index+len(word)] + '\\033[0m', end='')\n",
    "            index += len(word)\n",
    "        else:\n",
    "            print(text[index], end='')\n",
    "            index += 1\n",
    "\n",
    "def find_sub_list(sl,l):\n",
    "    sll=len(sl)\n",
    "    for ind in (i for i,e in enumerate(l) if e==sl[0]):\n",
    "        if l[ind:ind+sll]==sl:\n",
    "            return ind,ind+sll\n",
    "\n",
    "printred(\"There was a lot of persons.\", \"person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60585d07-0913-45d0-b9db-7214c221d0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLD dataset: Dataset({\n",
      "    features: ['source', 'source_id', 'source_id_text', 'title', 'date', 'place', 'text'],\n",
      "    num_rows: 1518717\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████████| 1518717/1518717 [00:12<00:00, 121230.57 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLD LATAM dataset: Dataset({\n",
      "    features: ['source', 'source_id', 'source_id_text', 'title', 'date', 'place', 'text'],\n",
      "    num_rows: 21310\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "old_dataset = Dataset.from_pandas(\n",
    "    pd.read_csv(\"./data/old-spanish-corpus-chunked.tsv\", sep=\"\\t\", dtype={'source_id': str, 'source_text_id': str})\n",
    ")\n",
    "print(\"OLD dataset:\", old_dataset)\n",
    "\n",
    "old_dataset_latam = old_dataset.filter(lambda example: example[\"source\"] == \"19th century Latam Newspapers\")\n",
    "print(\"OLD LATAM dataset:\", old_dataset_latam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9505ca6c-2651-47ad-87d5-009a2f332a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODERN dataset: Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 8214959\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "modern_dataset = load_dataset(\"large_spanish_corpus\", \"EUBookShop\", trust_remote_code=True)[\"train\"] # TODO: chage the modern spanish dataset\n",
    "print(\"MODERN dataset:\", modern_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc82813b-f17b-46f9-80e5-61335731251c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "HF_CHECKPOINT = \"dccuchile/bert-base-spanish-wwm-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(HF_CHECKPOINT)\n",
    "\n",
    "model_old = torch.load(\"./output/latam-old-spanish-beto-uncased.pt\")\n",
    "model_new = AutoModel.from_pretrained(HF_CHECKPOINT)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model_old = model_old.to(device)\n",
    "model_new = model_new.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78454522-2bdd-46af-9a28-2bd1f28c685e",
   "metadata": {},
   "outputs": [],
   "source": [
    "searchs = [\n",
    "    [\"gente\", \"jente\"],\n",
    "    [\"servidores\"],\n",
    "    [\"humanitaria\"],\n",
    "    [\"humor\"],\n",
    "    [\"privilegiado\", \"privilejiado\"], \n",
    "    [\"ventajosa\"],\n",
    "    [\"hombre\"],  \n",
    "    [\"placer\"], \n",
    "    [\"razón\", \"razon\"], \n",
    "    [\"juicio\"], \n",
    "    [\"excitación\", \"exitación\", \"exitacion\"],\n",
    "    [\"urbanidad\"],\n",
    "    [\"academia\"],\n",
    "    [\"miserable\"], \n",
    "    [\"nebulosas\", \"nebulosa\"],\n",
    "    [\"privado\"],\n",
    "    [\"diablo\"], \n",
    "    [\"luces\", \"luzes\"],\n",
    "    [\"genio\", \"jenio\"],\n",
    "    [\"mujeres\"]\n",
    "]\n",
    "\n",
    "MAX_N_OLD = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abddeb66-9a1e-46e0-a17c-574916a81279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gente: found 50 in OLD and 50 in NEW\n",
      "servidores: found 50 in OLD and 50 in NEW\n",
      "humanitaria: found 21 in OLD and 21 in NEW\n",
      "humor: found 50 in OLD and 50 in NEW\n",
      "privilegiado: found 47 in OLD and 47 in NEW\n",
      "ventajosa: found 26 in OLD and 26 in NEW\n",
      "hombre: found 50 in OLD and 50 in NEW\n",
      "placer: found 50 in OLD and 50 in NEW\n",
      "razón: found 50 in OLD and 50 in NEW\n",
      "juicio: found 50 in OLD and 50 in NEW\n",
      "excitación: found 42 in OLD and 39 in NEW\n",
      "urbanidad: found 37 in OLD and 10 in NEW\n",
      "academia: found 15 in OLD and 15 in NEW\n",
      "miserable: found 50 in OLD and 50 in NEW\n",
      "nebulosas: found 28 in OLD and 17 in NEW\n",
      "privado: found 50 in OLD and 50 in NEW\n",
      "diablo: found 50 in OLD and 50 in NEW\n",
      "luces: found 50 in OLD and 50 in NEW\n",
      "genio: found 50 in OLD and 50 in NEW\n",
      "mujeres: found 50 in OLD and 50 in NEW\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>orth</th>\n",
       "      <th>text</th>\n",
       "      <th>period</th>\n",
       "      <th>cluster_new</th>\n",
       "      <th>cluster_old</th>\n",
       "      <th>embedding_new</th>\n",
       "      <th>embedding_old</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gente</td>\n",
       "      <td>gente</td>\n",
       "      <td>Llevóle entonces a la azotea de \" Casa , que s...</td>\n",
       "      <td>old</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[tensor(0.0526), tensor(-0.0099), tensor(0.056...</td>\n",
       "      <td>[tensor(0.0583), tensor(-0.0013), tensor(0.032...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gente</td>\n",
       "      <td>jente</td>\n",
       "      <td>Um. 9. EL TEMA. NOVENA SESIÓN. A las 11 y 11 m...</td>\n",
       "      <td>old</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[tensor(0.0150), tensor(-0.0125), tensor(0.022...</td>\n",
       "      <td>[tensor(0.0208), tensor(0.0295), tensor(0.0194...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gente</td>\n",
       "      <td>jente</td>\n",
       "      <td>Verdaderamente cívicas y domésticas ; arrase l...</td>\n",
       "      <td>old</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[tensor(-0.0097), tensor(-0.0229), tensor(0.00...</td>\n",
       "      <td>[tensor(0.0218), tensor(0.0414), tensor(0.0301...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gente</td>\n",
       "      <td>jente</td>\n",
       "      <td>Llueven de 27 en 27 sobre mis costillas, como ...</td>\n",
       "      <td>old</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[tensor(-0.0174), tensor(-0.0051), tensor(0.01...</td>\n",
       "      <td>[tensor(-0.0280), tensor(0.0320), tensor(0.016...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gente</td>\n",
       "      <td>jente</td>\n",
       "      <td>do-el Pique-la Hormiga-la Pulga, un Ratón,dos ...</td>\n",
       "      <td>old</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[tensor(-8.6513e-05), tensor(0.0079), tensor(0...</td>\n",
       "      <td>[tensor(0.0080), tensor(0.0582), tensor(0.0359...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>mujeres</td>\n",
       "      <td>mujeres</td>\n",
       "      <td>Y en algunos países, como España, la diferenci...</td>\n",
       "      <td>new</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[tensor(0.0446), tensor(0.0081), tensor(0.0304...</td>\n",
       "      <td>[tensor(-0.0083), tensor(0.0119), tensor(0.013...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687</th>\n",
       "      <td>mujeres</td>\n",
       "      <td>mujeres</td>\n",
       "      <td>Mientras las propuestas del pacto de confianza...</td>\n",
       "      <td>new</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[tensor(-0.0235), tensor(-0.0301), tensor(0.08...</td>\n",
       "      <td>[tensor(-0.0370), tensor(-0.0170), tensor(0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>mujeres</td>\n",
       "      <td>mujeres</td>\n",
       "      <td>Y es evidente que el desempleo afecta mucho má...</td>\n",
       "      <td>new</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[tensor(0.0677), tensor(0.0124), tensor(0.0379...</td>\n",
       "      <td>[tensor(0.0153), tensor(-0.0008), tensor(0.036...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689</th>\n",
       "      <td>mujeres</td>\n",
       "      <td>mujeres</td>\n",
       "      <td>Agradecemos al ponente, Sr. Lage, que haya inc...</td>\n",
       "      <td>new</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[tensor(0.0355), tensor(-0.0040), tensor(0.042...</td>\n",
       "      <td>[tensor(-0.0151), tensor(-0.0020), tensor(0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>mujeres</td>\n",
       "      <td>mujeres</td>\n",
       "      <td>La creación de empleo va unida al desarrollo d...</td>\n",
       "      <td>new</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[tensor(0.0413), tensor(0.0093), tensor(0.0536...</td>\n",
       "      <td>[tensor(-0.0075), tensor(0.0047), tensor(0.049...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1691 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         word     orth                                               text  \\\n",
       "0       gente    gente  Llevóle entonces a la azotea de \" Casa , que s...   \n",
       "1       gente    jente  Um. 9. EL TEMA. NOVENA SESIÓN. A las 11 y 11 m...   \n",
       "2       gente    jente  Verdaderamente cívicas y domésticas ; arrase l...   \n",
       "3       gente    jente  Llueven de 27 en 27 sobre mis costillas, como ...   \n",
       "4       gente    jente  do-el Pique-la Hormiga-la Pulga, un Ratón,dos ...   \n",
       "...       ...      ...                                                ...   \n",
       "1686  mujeres  mujeres  Y en algunos países, como España, la diferenci...   \n",
       "1687  mujeres  mujeres  Mientras las propuestas del pacto de confianza...   \n",
       "1688  mujeres  mujeres  Y es evidente que el desempleo afecta mucho má...   \n",
       "1689  mujeres  mujeres  Agradecemos al ponente, Sr. Lage, que haya inc...   \n",
       "1690  mujeres  mujeres  La creación de empleo va unida al desarrollo d...   \n",
       "\n",
       "     period cluster_new cluster_old  \\\n",
       "0       old        None        None   \n",
       "1       old        None        None   \n",
       "2       old        None        None   \n",
       "3       old        None        None   \n",
       "4       old        None        None   \n",
       "...     ...         ...         ...   \n",
       "1686    new        None        None   \n",
       "1687    new        None        None   \n",
       "1688    new        None        None   \n",
       "1689    new        None        None   \n",
       "1690    new        None        None   \n",
       "\n",
       "                                          embedding_new  \\\n",
       "0     [tensor(0.0526), tensor(-0.0099), tensor(0.056...   \n",
       "1     [tensor(0.0150), tensor(-0.0125), tensor(0.022...   \n",
       "2     [tensor(-0.0097), tensor(-0.0229), tensor(0.00...   \n",
       "3     [tensor(-0.0174), tensor(-0.0051), tensor(0.01...   \n",
       "4     [tensor(-8.6513e-05), tensor(0.0079), tensor(0...   \n",
       "...                                                 ...   \n",
       "1686  [tensor(0.0446), tensor(0.0081), tensor(0.0304...   \n",
       "1687  [tensor(-0.0235), tensor(-0.0301), tensor(0.08...   \n",
       "1688  [tensor(0.0677), tensor(0.0124), tensor(0.0379...   \n",
       "1689  [tensor(0.0355), tensor(-0.0040), tensor(0.042...   \n",
       "1690  [tensor(0.0413), tensor(0.0093), tensor(0.0536...   \n",
       "\n",
       "                                          embedding_old  \n",
       "0     [tensor(0.0583), tensor(-0.0013), tensor(0.032...  \n",
       "1     [tensor(0.0208), tensor(0.0295), tensor(0.0194...  \n",
       "2     [tensor(0.0218), tensor(0.0414), tensor(0.0301...  \n",
       "3     [tensor(-0.0280), tensor(0.0320), tensor(0.016...  \n",
       "4     [tensor(0.0080), tensor(0.0582), tensor(0.0359...  \n",
       "...                                                 ...  \n",
       "1686  [tensor(-0.0083), tensor(0.0119), tensor(0.013...  \n",
       "1687  [tensor(-0.0370), tensor(-0.0170), tensor(0.02...  \n",
       "1688  [tensor(0.0153), tensor(-0.0008), tensor(0.036...  \n",
       "1689  [tensor(-0.0151), tensor(-0.0020), tensor(0.04...  \n",
       "1690  [tensor(-0.0075), tensor(0.0047), tensor(0.049...  \n",
       "\n",
       "[1691 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\"word\":[], \"orth\":[], \"text\":[], \"period\":[], \"cluster_new\":[], \"cluster_old\":[], \"embedding_new\":[], \"embedding_old\":[]}\n",
    "\n",
    "for search in searchs:\n",
    "    w = search[0]\n",
    "\n",
    "    i = 0\n",
    "    for example in old_dataset_latam:\n",
    "        text = example[\"text\"]\n",
    "        for s in search:\n",
    "            match = re.search(r'\\b' + re.escape(s) + r'\\b', text)\n",
    "            if match:\n",
    "                # Word found!\n",
    "                inp = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True, padding='max_length')\n",
    "                idx, idxF = find_sub_list(tokenizer(s)['input_ids'][1:-1], inp['input_ids'].tolist()[0])\n",
    "                assert tokenizer.decode(inp['input_ids'][0][idx:idxF]) == s, f\"Expected {s} but got {tokenizer.decode(inp['input_ids'][0][idx:idxF])}\"\n",
    "                with torch.no_grad():\n",
    "                    input_ids = inp[\"input_ids\"].to(device)\n",
    "                    attention_mask = inp[\"attention_mask\"].to(device)\n",
    "                    embedding_new_old = model_new(input_ids, attention_mask=attention_mask, output_hidden_states=True).last_hidden_state[0][idx].cpu()\n",
    "                    embedding_old_old = model_old(input_ids, attention_mask=attention_mask, output_hidden_states=True).hidden_states[-1][0][idx].cpu()\n",
    "\n",
    "                data['word'].append(w)\n",
    "                data['orth'].append(s)\n",
    "                data['text'].append(text)\n",
    "                data['period'].append('old')\n",
    "                data['cluster_new'].append(None)\n",
    "                data['cluster_old'].append(None)\n",
    "                data['embedding_new'].append(normalize(embedding_new_old, p=2, dim=-1))\n",
    "                data['embedding_old'].append(normalize(embedding_old_old, p=2, dim=-1))\n",
    "\n",
    "                i += 1\n",
    "                break\n",
    "        if i == MAX_N_OLD:\n",
    "            break\n",
    "    print(f\"{w}: found {i} in OLD \", end=\"\")\n",
    "\n",
    "    j = 0\n",
    "    MAX_N_NEW = i\n",
    "    for example in modern_dataset:\n",
    "        text = example[\"text\"]\n",
    "        match = re.search(r'\\b' + re.escape(w) + r'\\b', text)\n",
    "        if match:\n",
    "            # Word found!\n",
    "            inp = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True, padding='max_length')\n",
    "            idx, idxF = find_sub_list(tokenizer(w)['input_ids'][1:-1], inp['input_ids'].tolist()[0])\n",
    "            assert tokenizer.decode(inp['input_ids'][0][idx:idxF]) == w, f\"Expected {w} but got {tokenizer.decode(inp['input_ids'][0][idx:idxF])}\"\n",
    "            with torch.no_grad():\n",
    "                input_ids = inp[\"input_ids\"].to(device)\n",
    "                attention_mask = inp[\"attention_mask\"].to(device)\n",
    "                embedding_new_new = model_new(input_ids, attention_mask=attention_mask, output_hidden_states=True).last_hidden_state[0][idx].cpu()\n",
    "                embedding_old_new = model_old(input_ids, attention_mask=attention_mask, output_hidden_states=True).hidden_states[-1][0][idx].cpu()\n",
    "            \n",
    "            data['word'].append(w)\n",
    "            data['orth'].append(w)\n",
    "            data['text'].append(text)\n",
    "            data['period'].append('new')\n",
    "            data['cluster_new'].append(None)\n",
    "            data['cluster_old'].append(None)\n",
    "            data['embedding_new'].append(normalize(embedding_new_new, p=2, dim=-1))\n",
    "            data['embedding_old'].append(normalize(embedding_old_new, p=2, dim=-1))\n",
    "            \n",
    "            j += 1\n",
    "        if j == MAX_N_NEW:\n",
    "            break\n",
    "    print(f\"and {j} in NEW\")\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "591d1430-26b5-48cd-a2a2-1bc68d52576a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_silhouette(tensors, kmeans):\n",
    "    n = kmeans.n_clusters\n",
    "    labels = kmeans.labels_\n",
    "    if n == 1: return 0 # doesn't allow 1-cluster solutions\n",
    "    X = np.array([tensor.flatten().numpy() for tensor in tensors])\n",
    "    return silhouette_score(X, labels=labels, metric='euclidean')\n",
    "\n",
    "def get_delta_score(tensors, kmeans):\n",
    "    # TODO: implement delta_score\n",
    "    return\n",
    "\n",
    "def elbow_method(inertia_values):\n",
    "    deltas = []\n",
    "    for i in range(1, len(inertia_values)):\n",
    "        deltas.append(inertia_values[i - 1] - inertia_values[i])\n",
    "    max_curvature_index = deltas.index(max(deltas))\n",
    "    return max_curvature_index + 2\n",
    "\n",
    "def clustering(df, metric):\n",
    "    best_score_new, best_n_new, inertias_new = -1, 0, []\n",
    "    best_score_old, best_n_old, inertias_old = -1, 0, []\n",
    "\n",
    "    for n in range(1, len(df)):\n",
    "        kmeans_new = KMeans(n_clusters=n, random_state=0, n_init='auto')\n",
    "        kmeans_new.fit([t.numpy() for t in df['embedding_new'].tolist()])\n",
    "        df[f'cluster_new_{n}'] = kmeans_new.labels_\n",
    "        if (metric == 'inertia'):\n",
    "            inertias_new.append(kmeans_new.inertia_)\n",
    "        else:\n",
    "            score_new = compute_metric(df['embedding_new'], kmeans_new, metric)\n",
    "            if (metric == 'silhouette') and (score_new > best_score_new):\n",
    "                best_score_new, best_n_new = score_new, n\n",
    "            elif (metric == 'compactness') and (score_new > best_score_new):\n",
    "                best_score_new, best_n_new = score_new, n\n",
    "\n",
    "        kmeans_old = KMeans(n_clusters=n, random_state=0, n_init='auto')\n",
    "        kmeans_old.fit([t.numpy() for t in df['embedding_old'].tolist()])\n",
    "        df[f'cluster_old_{n}'] = kmeans_old.labels_\n",
    "        if (metric == 'inertia'):\n",
    "            inertias_old.append(kmeans_old.inertia_)\n",
    "        else:\n",
    "            score_old = compute_metric(df['embedding_old'], kmeans_old, metric)\n",
    "            if (metric == 'silhouette') and (score_old > best_score_old):\n",
    "                best_score_old, best_n_old = score_old, n\n",
    "            elif (metric == 'compactness') and (score_old > best_score_old):\n",
    "                best_score_old, best_n_old = score_old, n\n",
    "    \n",
    "    if metric == 'inertia':\n",
    "        best_n_new = elbow_method(inertias_new)\n",
    "        best_n_old = elbow_method(inertias_old)\n",
    "        if SHOULD_PRINT:\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.plot(range(1, len(inertias_new) + 1), inertias_new, marker='o')\n",
    "            plt.xlabel('Number of clusters')\n",
    "            plt.ylabel('Inertia')\n",
    "            plt.title('Inertia (new model)')\n",
    "\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.plot(range(1, len(inertias_old) + 1), inertias_old, marker='o')\n",
    "            plt.xlabel('Number of clusters')\n",
    "            plt.ylabel('Inertia')\n",
    "            plt.title('Inertia (old model)')\n",
    "\n",
    "            plt.suptitle(f\"Inertia for word '{df.iloc[0]['word']}'\")\n",
    "            plt.show()\n",
    "\n",
    "    df['cluster_new'] = df[f'cluster_new_{best_n_new}']\n",
    "    df = df.drop(columns=[f'cluster_new_{n}' for n in range(1, len(df))])\n",
    "    df['cluster_old'] = df[f'cluster_old_{best_n_old}']\n",
    "    df = df.drop(columns=[f'cluster_old_{n}' for n in range(1, len(df))])\n",
    "\n",
    "    if SHOULD_PRINT:\n",
    "        print(\"Best number of clusters (new):\", best_n_new, f\"[max {len(df)}]\")\n",
    "        print(\"Best number of clusters (old):\", best_n_old, f\"[max {len(df)}]\")\n",
    "    return df\n",
    "\n",
    "def compute_metric(tensors, kmeans, method=\"silhouette\"):\n",
    "    return get_silhouette(tensors, kmeans) if method == \"silhouette\" else get_delta_score(tensors, kmeans)\n",
    "\n",
    "def cluster_df(df, metric=\"silhouette\"):\n",
    "    result_df = pd.DataFrame()\n",
    "    for word, group in df.groupby('word'):\n",
    "        if SHOULD_PRINT:\n",
    "            print(f\"{word}\")\n",
    "        group_cl = clustering(group, metric)\n",
    "        result_df = pd.concat([result_df, group_cl], ignore_index=True)\n",
    "        assert len(group) == len(group_cl), f\"{len(group)} != {len(group_cl)} for word {word}\"\n",
    "\n",
    "    #result_df = result_df.set_index('id')\n",
    "    #result_df = result_df.reindex(df['id'])\n",
    "    result_df = result_df.drop(columns=[\"embedding_new\", \"embedding_old\"])\n",
    "    return result_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "728e11f5-cdb5-47cd-bbd6-0e1c308d05fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "academia\n",
      "Best number of clusters (new): 2 [max 30]\n",
      "Best number of clusters (old): 2 [max 30]\n",
      "diablo\n",
      "Best number of clusters (new): 4 [max 100]\n",
      "Best number of clusters (old): 2 [max 100]\n",
      "excitación\n",
      "Best number of clusters (new): 2 [max 81]\n",
      "Best number of clusters (old): 2 [max 81]\n",
      "genio\n",
      "Best number of clusters (new): 3 [max 100]\n",
      "Best number of clusters (old): 2 [max 100]\n",
      "gente\n",
      "Best number of clusters (new): 2 [max 100]\n",
      "Best number of clusters (old): 2 [max 100]\n",
      "hombre\n",
      "Best number of clusters (new): 2 [max 100]\n",
      "Best number of clusters (old): 2 [max 100]\n",
      "humanitaria\n",
      "Best number of clusters (new): 2 [max 42]\n",
      "Best number of clusters (old): 2 [max 42]\n",
      "humor\n",
      "Best number of clusters (new): 2 [max 100]\n",
      "Best number of clusters (old): 2 [max 100]\n",
      "juicio\n",
      "Best number of clusters (new): 3 [max 100]\n",
      "Best number of clusters (old): 2 [max 100]\n",
      "luces\n",
      "Best number of clusters (new): 3 [max 100]\n",
      "Best number of clusters (old): 2 [max 100]\n",
      "miserable\n",
      "Best number of clusters (new): 2 [max 100]\n",
      "Best number of clusters (old): 2 [max 100]\n",
      "mujeres\n",
      "Best number of clusters (new): 2 [max 100]\n",
      "Best number of clusters (old): 2 [max 100]\n",
      "nebulosas\n",
      "Best number of clusters (new): 18 [max 45]\n",
      "Best number of clusters (old): 2 [max 45]\n",
      "placer\n",
      "Best number of clusters (new): 4 [max 100]\n",
      "Best number of clusters (old): 3 [max 100]\n",
      "privado\n",
      "Best number of clusters (new): 4 [max 100]\n",
      "Best number of clusters (old): 2 [max 100]\n",
      "privilegiado\n",
      "Best number of clusters (new): 2 [max 94]\n",
      "Best number of clusters (old): 3 [max 94]\n",
      "razón\n",
      "Best number of clusters (new): 22 [max 100]\n",
      "Best number of clusters (old): 2 [max 100]\n",
      "servidores\n",
      "Best number of clusters (new): 2 [max 100]\n",
      "Best number of clusters (old): 2 [max 100]\n",
      "urbanidad\n",
      "Best number of clusters (new): 5 [max 47]\n",
      "Best number of clusters (old): 2 [max 47]\n",
      "ventajosa\n",
      "Best number of clusters (new): 2 [max 52]\n",
      "Best number of clusters (old): 35 [max 52]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "      <th>orth</th>\n",
       "      <th>text</th>\n",
       "      <th>period</th>\n",
       "      <th>cluster_new</th>\n",
       "      <th>cluster_old</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>academia</td>\n",
       "      <td>academia</td>\n",
       "      <td>151 elipsis cuando se suprime el nombre ó el v...</td>\n",
       "      <td>old</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>academia</td>\n",
       "      <td>academia</td>\n",
       "      <td>REDACTOR, JOSH L. CAMACHO La Ciencia, con su p...</td>\n",
       "      <td>old</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>academia</td>\n",
       "      <td>academia</td>\n",
       "      <td>Yaro, por no tener partida en el Presupuesto d...</td>\n",
       "      <td>old</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>academia</td>\n",
       "      <td>academia</td>\n",
       "      <td>fué destinado al Convento de Murcia en cuya cé...</td>\n",
       "      <td>old</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>academia</td>\n",
       "      <td>academia</td>\n",
       "      <td>Las aptitudes físicas y morales que necesita q...</td>\n",
       "      <td>old</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>1686</td>\n",
       "      <td>ventajosa</td>\n",
       "      <td>ventajosa</td>\n",
       "      <td>El BEI lanza una oferta de canje de deuda por ...</td>\n",
       "      <td>new</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687</th>\n",
       "      <td>1687</td>\n",
       "      <td>ventajosa</td>\n",
       "      <td>ventajosa</td>\n",
       "      <td>La resolución de las controversias entre la ad...</td>\n",
       "      <td>new</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>1688</td>\n",
       "      <td>ventajosa</td>\n",
       "      <td>ventajosa</td>\n",
       "      <td>223 h) aprobará en un plazo de treinta días la...</td>\n",
       "      <td>new</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689</th>\n",
       "      <td>1689</td>\n",
       "      <td>ventajosa</td>\n",
       "      <td>ventajosa</td>\n",
       "      <td>La consulta es especialmente ventajosa cuando ...</td>\n",
       "      <td>new</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>1690</td>\n",
       "      <td>ventajosa</td>\n",
       "      <td>ventajosa</td>\n",
       "      <td>• primer paso: en la fase previa a la inversió...</td>\n",
       "      <td>new</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1691 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index       word       orth  \\\n",
       "0         0   academia   academia   \n",
       "1         1   academia   academia   \n",
       "2         2   academia   academia   \n",
       "3         3   academia   academia   \n",
       "4         4   academia   academia   \n",
       "...     ...        ...        ...   \n",
       "1686   1686  ventajosa  ventajosa   \n",
       "1687   1687  ventajosa  ventajosa   \n",
       "1688   1688  ventajosa  ventajosa   \n",
       "1689   1689  ventajosa  ventajosa   \n",
       "1690   1690  ventajosa  ventajosa   \n",
       "\n",
       "                                                   text period  cluster_new  \\\n",
       "0     151 elipsis cuando se suprime el nombre ó el v...    old            0   \n",
       "1     REDACTOR, JOSH L. CAMACHO La Ciencia, con su p...    old            0   \n",
       "2     Yaro, por no tener partida en el Presupuesto d...    old            0   \n",
       "3     fué destinado al Convento de Murcia en cuya cé...    old            0   \n",
       "4     Las aptitudes físicas y morales que necesita q...    old            0   \n",
       "...                                                 ...    ...          ...   \n",
       "1686  El BEI lanza una oferta de canje de deuda por ...    new            1   \n",
       "1687  La resolución de las controversias entre la ad...    new            0   \n",
       "1688  223 h) aprobará en un plazo de treinta días la...    new            0   \n",
       "1689  La consulta es especialmente ventajosa cuando ...    new            1   \n",
       "1690  • primer paso: en la fase previa a la inversió...    new            0   \n",
       "\n",
       "      cluster_old  \n",
       "0               1  \n",
       "1               1  \n",
       "2               1  \n",
       "3               0  \n",
       "4               1  \n",
       "...           ...  \n",
       "1686           28  \n",
       "1687            2  \n",
       "1688            2  \n",
       "1689            8  \n",
       "1690           11  \n",
       "\n",
       "[1691 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SHOULD_PRINT = True\n",
    "CLUSTERING_METRIC = \"silhouette\" # \"silhouette\", \"inertia\" or \"delta\"\n",
    "# TODO: Add new option (after delta metric) to allow differentiating between period clustering (different clustering for each) ...\n",
    "# ... And TODO: THEN, compare the centroids of the clusters to determine wethere it's the same cluster or not\n",
    "\n",
    "result_df = cluster_df(df, CLUSTERING_METRIC)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e593cfc2-d337-429d-8cec-0f765486eeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('./output/ssd-clustered-silhouette.tsv', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
